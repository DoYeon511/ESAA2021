{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "모델훈련.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKIh_eUrRGrh"
      },
      "source": [
        "# **4. 모델 훈련 연습문제**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfq9au-8RLzV"
      },
      "source": [
        "### 1) 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzcik5TKRSbt"
      },
      "source": [
        "보통은 확률적 경사 하강법(SGD), 미니배치 경사 하강법을 사용한다. 훈련 세트의 크기가 메모리에 맞다면 배치 경사 하강법도 가능하다. \n",
        "\n",
        "하지만 정규방정식은 계산 복잡도가 \"특성의 갯수\"에 따라 매우 빠르게 증가하기에 사용할 수 없다\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9gWwKzYRrnz"
      },
      "source": [
        "### 9) 릿지 회귀를 사용했을 때 훈련 오차와 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 α 를 증가시켜야할까요, 아니면 줄여야 할까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I14Vc7qnSXmo"
      },
      "source": [
        "* 훈련 오차와 검증 오차가 비슷하므로, 단순한 모델이라고 유추할 수 있다.\n",
        "* 단순한 모형의 경우 분산은 적지만, 편향이 크다. \n",
        "* 따라서, 높은 편향이 문제이다.\n",
        "* 편향을 개선하기 위해서는 α 를 감소시켜야 한다.\n",
        "\n",
        "훈련 오차와 검증 오차가 비슷하다는 것을 과소적합되었다는 의미이므로 높은 편향이 문제이다.(편향이 높을수록 과소적합되기 쉽고 분산이 높을 수록 과대적합되기 쉽다. 따라서 α를 감소시켜야한다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKB1N5zoSYuQ"
      },
      "source": [
        "### 10) 다음과 같이 사용해야 하는 이유는?\n",
        "\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "\n",
        "\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1fa5fWsSj1q"
      },
      "source": [
        "1. 규제가 약간 있는 것이 대부분의 경우에 좋으므로, 일반적으로 평범한 선형 회귀는 피해야 한다.\n",
        "2. 릿지가 기본, 쓰이는 특성이 적으면 라쏘나 엘라스틱넷이 더 좋다.\n",
        "3. 특성 수가 훈련 샘플 수보다 많거나 특성 일부가 강하게 연관되어 있을경우, 보통 라쏘가 문제를 일으키므로 엘라스틱넷을 선호한다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXIoqwmOjePT"
      },
      "source": [
        "### 12) 다음 사이트에 들어가서 연습문제 12번 일부를 필사하세요.\n",
        "\n",
        "https://github.com/rickiepark/handson-ml2/blob/master/04_training_linear_models.ipynb\n",
        "\n",
        "- 67번 셀 부터 80번 셀 까지 필사하시면 됩니다.\n",
        "\n",
        "- 시간이 남는다면 그 이후 코드까지 필사하셔도 좋습니다.\n",
        "\n",
        "- 수식이 설명되어있는 부분을 보고싶으면 그 부분을 그대로 복사하여 텍스트 창에 붙여넣기 한 다음 직접 실행시키시면 확인해볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJDvfjpbAhpw"
      },
      "source": [
        "## 12. 조기 종료를 사용한 배치 경사 하강법으로 소프트맥스 회귀 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac3I5wR-DWqf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHKnJWilCvf9",
        "outputId": "87a9e1db-2b00-42e5-a8ea-c47fd3149e2c"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "list(iris.keys())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1cf8nP7REj6"
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = iris[\"target\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT6qpx_7DJTA"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X] \n",
        "# 모든 샘플에 편향을 추가(X0 = 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vusZ2R6KDR1Z"
      },
      "source": [
        "np.random.seed(2042)  # 결과를 일정하게 유지하기 위해 랜덤 시드를 지정"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JefEJHsCDgYI"
      },
      "source": [
        "# train_test_split() 함수를 사용하지 않고 데이터셋을 훈련 세트, 검증 세트, 테스트 세트로 나눔\n",
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)  # 무작위로 섞인 배열을 만듦\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rKm574REJWv"
      },
      "source": [
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1\n",
        "    m = len(y)\n",
        "    Y_one_hot = np.zeros((m, n_classes))\n",
        "    Y_one_hot[np.arange(m), y] = 1\n",
        "    return Y_one_hot"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NKHXHVaEezZ",
        "outputId": "6addc743-1124-4bba-ae19-72f3cacbb51c"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 1, 1, 0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh6o-SMIEm1-",
        "outputId": "e1a3dfb4-4591-4570-f7e1-02a4a4a070ca"
      },
      "source": [
        "to_one_hot(y_train[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5lq-AQHEq73"
      },
      "source": [
        "# 훈련 세트와 테스트 세트의 타깃 클래스 확률을 담은 행렬을 만듦\n",
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10SJM2afFOiw"
      },
      "source": [
        "* 소프트맥스 함수\n",
        "$\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsR-V53BFKWf"
      },
      "source": [
        "def softmax(logits):\n",
        "    exps = np.exp(logits)\n",
        "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
        "    return exps / exp_sums"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDOSpmg-FNGK"
      },
      "source": [
        "n_inputs = X_train.shape[1] \n",
        "n_outputs = len(np.unique(y_train))  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dD7t1DcFfRu",
        "outputId": "f4b1f38c-b2a6-4039-e64c-67295d5b5c75"
      },
      "source": [
        "n_inputs   # 특성 2개(꽃잎의 길이, 꽃잎의 넓이)와 편향(X0 = 1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9RWf7V0FeYP",
        "outputId": "dc8b5f50-66cd-4224-ed86-3ce9928e41a1"
      },
      "source": [
        "n_outputs   # 3개의 붓꽃 클래스"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoJCivc3GKXj"
      },
      "source": [
        "비용함수\n",
        "\n",
        "$J(\\mathbf{\\Theta}) = \\dfrac{1}{m}\\sum\\limits{i=1}^{m}\\sum\\limits{k=1}^{K}{y_k^{(i)}\\log\\left(\\hat{p}_k^{(i)}\\right)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbrzGQtgGVrC"
      },
      "source": [
        "그레디언트 공식\n",
        "\n",
        "$\\nabla_{\\mathbf{\\theta}^{(k)}} \\, J(\\mathbf{\\Theta}) = \\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{ \\left ( \\hat{p}^{(i)}_k - y_k^{(i)} \\right ) \\mathbf{x}^{(i)}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxYUPNtiGdlB"
      },
      "source": [
        "* $\\hat{p}_k^{(i)} = 0$이면 $\\log\\left(\\hat{p}_k^{(i)}\\right)$를 계산할 수 없습니다. nan 값을 피하기 위해 $\\log\\left(\\hat{p}_k^{(i)}\\right)$에 아주 작은 값 $\\epsilon$ 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZgkJzzUFmN4",
        "outputId": "47a4da99-a075-47fd-f967-9fe93c9ba10c"
      },
      "source": [
        "eta = 0.01\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))  # 비용함수\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5.446205811872683\n",
            "500 0.8350062641405651\n",
            "1000 0.6878801447192402\n",
            "1500 0.6012379137693314\n",
            "2000 0.5444496861981872\n",
            "2500 0.5038530181431525\n",
            "3000 0.47292289721922487\n",
            "3500 0.44824244188957774\n",
            "4000 0.42786510939287936\n",
            "4500 0.41060071429187134\n",
            "5000 0.3956780375390374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgPVQeenHO4z",
        "outputId": "33b8868d-cfa6-4bb3-fde1-54719f7b9332"
      },
      "source": [
        "Theta"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.32094157, -0.6501102 , -2.99979416],\n",
              "       [-1.1718465 ,  0.11706172,  0.10507543],\n",
              "       [-0.70224261, -0.09527802,  1.4786383 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_g7cOszHTS3",
        "outputId": "66e89116-7b96-45ab-db73-7037a76e37de"
      },
      "source": [
        "# 검증 세트에 대한 예측 정확도 확인\n",
        "\n",
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nemr12FtHbX7",
        "outputId": "6cdd63fc-4804-4226-9534-f2c8686c32b1"
      },
      "source": [
        "# l2 규제 추가 -> 손실에 l2 페널티가 추가되었고 그래디언트에도 항이 추가됨 (Theta의 첫 번째 원소는 편향이므로 규제하지 않음)\n",
        "\n",
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # 규제 하이퍼파라미터\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "        loss = xentropy_loss + alpha * l2_loss\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 6.629842469083912\n",
            "500 0.5339667976629505\n",
            "1000 0.5036400750148942\n",
            "1500 0.49468910594603216\n",
            "2000 0.4912968418075476\n",
            "2500 0.48989924700933296\n",
            "3000 0.4892990598451198\n",
            "3500 0.48903512443978603\n",
            "4000 0.4889173621830818\n",
            "4500 0.48886433374493027\n",
            "5000 0.48884031207388184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qucZb9RDHwGW",
        "outputId": "e4e60bba-6c4a-4eb2-88a5-a31caad12bc6"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSlT5jK_H147"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}